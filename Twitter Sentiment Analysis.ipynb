{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "bf81486e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import string\n",
    "import numpy as np \n",
    "import random\n",
    "import pandas as pd \n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "%matplotlib inline\n",
    "from plotly import graph_objs as go\n",
    "import plotly.express as px\n",
    "import plotly.figure_factory as ff\n",
    "from collections import Counter\n",
    "\n",
    "from PIL import Image\n",
    "from wordcloud import WordCloud, STOPWORDS, ImageColorGenerator\n",
    "\n",
    "\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "\n",
    "from tqdm import tqdm\n",
    "import os\n",
    "import nltk\n",
    "import spacy\n",
    "import random\n",
    "from spacy.util import compounding\n",
    "from spacy.util import minibatch\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ec7a9a54",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>_key</th>\n",
       "      <th>tweet_author</th>\n",
       "      <th>tweet_text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1374140386071961602</td>\n",
       "      <td>Hematopoiesis News</td>\n",
       "      <td>‚öïÔ∏è Scientists conducted a Phase II study of ac...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1374032432173842437</td>\n",
       "      <td>Michael Wang, MD</td>\n",
       "      <td>This phase 2 Acalabrutinib-Venetoclax (AV) tri...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1373902876553048065</td>\n",
       "      <td>1stOncology</td>\n",
       "      <td>#NICE backs #AstraZenecas #Calquence for #CLL ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1373656782367813635</td>\n",
       "      <td>Toby Eyre</td>\n",
       "      <td>#acalabrutinib is a valuable option in pts int...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1372941634334232586</td>\n",
       "      <td>Lymphoma Hub</td>\n",
       "      <td>NICE has recommended the use of acalabrutinib ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  _key        tweet_author  \\\n",
       "0  1374140386071961602  Hematopoiesis News   \n",
       "1  1374032432173842437    Michael Wang, MD   \n",
       "2  1373902876553048065         1stOncology   \n",
       "3  1373656782367813635           Toby Eyre   \n",
       "4  1372941634334232586        Lymphoma Hub   \n",
       "\n",
       "                                          tweet_text  \n",
       "0  ‚öïÔ∏è Scientists conducted a Phase II study of ac...  \n",
       "1  This phase 2 Acalabrutinib-Venetoclax (AV) tri...  \n",
       "2  #NICE backs #AstraZenecas #Calquence for #CLL ...  \n",
       "3  #acalabrutinib is a valuable option in pts int...  \n",
       "4  NICE has recommended the use of acalabrutinib ...  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.read_csv(\"C:\\\\Users\\\\Ansh\\\\Downloads\\\\tweets.csv\")\n",
    "# here i am printing fisrt five line of dataset\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d39e73a5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(43347, 3)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b2e73df0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>_key</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>4.334700e+04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>1.003292e+18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>2.313927e+17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>5.505794e+17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>8.006620e+17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>1.011270e+18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>1.204047e+18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>1.374141e+18</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               _key\n",
       "count  4.334700e+04\n",
       "mean   1.003292e+18\n",
       "std    2.313927e+17\n",
       "min    5.505794e+17\n",
       "25%    8.006620e+17\n",
       "50%    1.011270e+18\n",
       "75%    1.204047e+18\n",
       "max    1.374141e+18"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c2088574",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "_key            0\n",
       "tweet_author    0\n",
       "tweet_text      0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "702342f8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>_key</th>\n",
       "      <th>tweet_author</th>\n",
       "      <th>tweet_text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1374140386071961602</td>\n",
       "      <td>Hematopoiesis News</td>\n",
       "      <td>‚öïÔ∏è Scientists conducted a Phase II study of ac...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1374032432173842437</td>\n",
       "      <td>Michael Wang, MD</td>\n",
       "      <td>This phase 2 Acalabrutinib-Venetoclax (AV) tri...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1373902876553048065</td>\n",
       "      <td>1stOncology</td>\n",
       "      <td>#NICE backs #AstraZenecas #Calquence for #CLL ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1373656782367813635</td>\n",
       "      <td>Toby Eyre</td>\n",
       "      <td>#acalabrutinib is a valuable option in pts int...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1372941634334232586</td>\n",
       "      <td>Lymphoma Hub</td>\n",
       "      <td>NICE has recommended the use of acalabrutinib ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  _key        tweet_author  \\\n",
       "0  1374140386071961602  Hematopoiesis News   \n",
       "1  1374032432173842437    Michael Wang, MD   \n",
       "2  1373902876553048065         1stOncology   \n",
       "3  1373656782367813635           Toby Eyre   \n",
       "4  1372941634334232586        Lymphoma Hub   \n",
       "\n",
       "                                          tweet_text  \n",
       "0  ‚öïÔ∏è Scientists conducted a Phase II study of ac...  \n",
       "1  This phase 2 Acalabrutinib-Venetoclax (AV) tri...  \n",
       "2  #NICE backs #AstraZenecas #Calquence for #CLL ...  \n",
       "3  #acalabrutinib is a valuable option in pts int...  \n",
       "4  NICE has recommended the use of acalabrutinib ...  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "39cedd27",
   "metadata": {},
   "outputs": [],
   "source": [
    "def edits1(word):\n",
    "    letters='abcdefghijklmnopqrstuvwxyz'\n",
    "    splits=[(word[:i], word[i:]) for i in range(len(word)+1)]\n",
    "    deletes=[L+R[1:] for L,R in splits if R]\n",
    "    transposes=[L+R[1] +R[0] + R[2:] for L,R in splits if len(R)>1]\n",
    "    replaces = [L+c+R[1:] for L,R in splits if R for c in letters]\n",
    "    inserts = [L+c+ R for L,R in splits for c in letters]\n",
    "    return set(deletes+transposes+replaces+inserts)\n",
    "def edits2(word):\n",
    "    return(e2 for e1 in edits1(word) for e2 in edits1(e1))\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "6aff298c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_spaces(text):\n",
    "    text=text.strip()\n",
    "    text=text.split()\n",
    "    return ' '.join(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "17b9c6b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "contraction = {'cause':'because',\n",
    "              'aint': 'am not',\n",
    "              'aren\\'t': 'are not'}\n",
    "\n",
    "def mapping_replacer(x,dic):\n",
    "    for words in dic.keys():\n",
    "        if ' ' + words + ' ' in x:\n",
    "            x=x.replace(' '+ words +' ' ,' '+dic[words]+' ' )\n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "c2c4e22f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Error loading punkit: Package 'punkit' not found in index\n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "nltk.download('punkit')\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.stem.wordnet import WordNetLemmatizer\n",
    "from nltk.stem.lancaster import LancasterStemmer\n",
    "\n",
    "nltk.LancasterStemmer\n",
    "ls = LancasterStemmer()\n",
    "lem = WordNetLemmatizer()\n",
    "def lexicon_normalization(text):\n",
    "    words = word_tokenize(text) \n",
    "    \n",
    "    \n",
    "    # 1- Stemming\n",
    "    words_stem = [ls.stem(w) for w in words]\n",
    "    \n",
    "    # 2- Lemmatization\n",
    "    words_lem = [lem.lemmatize(w) for w in words_stem]\n",
    "    return words_lem\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "16222474",
   "metadata": {},
   "outputs": [],
   "source": [
    "import emoji\n",
    "import re \n",
    "#from emot.emo_unicode import UNICODE_EMO\n",
    "def convert_emojis(text):\n",
    "    for emot in emoji.UNICODE_EMOJI:\n",
    "        text = re.sub(r'('+emot+')', \"_\".join(emoji.UNICODE_EMOJI[emot].replace(\",\",\"\").replace(\":\",\"\").split()), text)\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "385b5c94",
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_text(text):\n",
    "    '''Make text lowercase, remove text in square brackets,remove links,remove punctuation\n",
    "    and remove words containing numbers.'''\n",
    "    text = str(text).lower()\n",
    "    text = re.sub('\\[.*?\\]', '', text)\n",
    "    text = re.sub('https?://\\S+|www\\.\\S+', '', text)\n",
    "    text = re.sub('<.*?>+', '', text)\n",
    "    text = re.sub('[%s]' % re.escape(string.punctuation), '', text)\n",
    "    text = re.sub('\\n', '', text)\n",
    "    text = re.sub('\\w*\\d\\w*', '', text)\n",
    "    text = re.sub('\\'','', text)\n",
    "    \n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "8e164dfc",
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import Counter\n",
    "def remove_stopword(text):\n",
    "    stop_words = stopwords.words('english')\n",
    "    stopwords_dict = Counter(stop_words)\n",
    "    text = ' '.join([word for word in text.split() if word not in stopwords_dict])\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "fcb9c8ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenise(text):\n",
    "    words = word_tokenize(text) \n",
    "    return words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "00799fa0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "data['tweet_text'] = data['tweet_text'].map(lambda x: re.sub(r'\\W+', ' ', x))\n",
    "data['tweet_text'] = data['tweet_text'].replace(r'\\W+', ' ', regex=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "8a2abb37",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0         Scientists conducted a Phase II study of acal...\n",
       "1        This phase 2 Acalabrutinib Venetoclax AV trial...\n",
       "2         NICE backs AstraZenecas Calquence for CLL htt...\n",
       "3         acalabrutinib is a valuable option in pts int...\n",
       "4        NICE has recommended the use of acalabrutinib ...\n",
       "                               ...                        \n",
       "43342    Hanging out with Friends FF CLL Happiness http...\n",
       "43343    Hanging out with Friends FF CLL Happiness http...\n",
       "43344    Zusatznutzen von Idelalisib ist weder f√ºr CLL ...\n",
       "43345     Hematolog√≠a PTK2 EXPRESSION AND IMMUNOCHEMOTH...\n",
       "43346     Hematolog√≠a MUTATIONS IN TLR MYD88 PATHWAY ID...\n",
       "Name: tweet_text, Length: 43347, dtype: object"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.tweet_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "523ae3ed",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>_key</th>\n",
       "      <th>tweet_author</th>\n",
       "      <th>tweet_text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1374140386071961602</td>\n",
       "      <td>Hematopoiesis News</td>\n",
       "      <td>Scientists conducted a Phase II study of acal...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1374032432173842437</td>\n",
       "      <td>Michael Wang MD</td>\n",
       "      <td>This phase 2 Acalabrutinib Venetoclax AV trial...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1373902876553048065</td>\n",
       "      <td>1stOncology</td>\n",
       "      <td>NICE backs AstraZenecas Calquence for CLL htt...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1373656782367813635</td>\n",
       "      <td>Toby Eyre</td>\n",
       "      <td>acalabrutinib is a valuable option in pts int...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1372941634334232586</td>\n",
       "      <td>Lymphoma Hub</td>\n",
       "      <td>NICE has recommended the use of acalabrutinib ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  _key        tweet_author  \\\n",
       "0  1374140386071961602  Hematopoiesis News   \n",
       "1  1374032432173842437     Michael Wang MD   \n",
       "2  1373902876553048065         1stOncology   \n",
       "3  1373656782367813635           Toby Eyre   \n",
       "4  1372941634334232586        Lymphoma Hub   \n",
       "\n",
       "                                          tweet_text  \n",
       "0   Scientists conducted a Phase II study of acal...  \n",
       "1  This phase 2 Acalabrutinib Venetoclax AV trial...  \n",
       "2   NICE backs AstraZenecas Calquence for CLL htt...  \n",
       "3   acalabrutinib is a valuable option in pts int...  \n",
       "4  NICE has recommended the use of acalabrutinib ...  "
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "4f03cfda",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = data.groupby(by=['tweet_author']).count()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "2cdb9d35",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.rename(columns = {'tweet_author':'Author', 'tweet_text':''}, inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "0ef5acea",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>_key</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>tweet_author</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <td>41</td>\n",
       "      <td>41</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Adam Grant</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>AiMS</th>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Anyii Vega</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>AplusA_France</th>\n",
       "      <td>10</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ùó°ùó∂ùóµùóÆùóø ùóóùó≤ùòÄùóÆùó∂ ùó†ùóó</th>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ùòÆùò¶ùò≠·∂ú</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ùôÖùô§ùôùùô£ ùôíùôñùô°ùô°</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ùô∞ùöùùöéùöñùöîùöõùöíùöúùöùùöäùöïùöï</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ùö¢ùöòùöòùöóùöúùöûùöóùöê ùöéùöùùöë ùöÜùöíùöùùöë ùöÉùöòùöîùöéùöó ùöÇùöéùöïùöïùöéùöõ</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>9269 rows √ó 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                _key    \n",
       "tweet_author                            \n",
       "                                  41  41\n",
       " Adam Grant                        1   1\n",
       " AiMS                              3   3\n",
       " Anyii Vega                        1   1\n",
       " AplusA_France                    10  10\n",
       "...                              ...  ..\n",
       "ùó°ùó∂ùóµùóÆùóø ùóóùó≤ùòÄùóÆùó∂ ùó†ùóó                     3   3\n",
       "ùòÆùò¶ùò≠·∂ú                               1   1\n",
       "ùôÖùô§ùôùùô£ ùôíùôñùô°ùô°                          1   1\n",
       "ùô∞ùöùùöéùöñùöîùöõùöíùöúùöùùöäùöïùöï                       1   1\n",
       "ùö¢ùöòùöòùöóùöúùöûùöóùöê ùöéùöùùöë ùöÜùöíùöùùöë ùöÉùöòùöîùöéùöó ùöÇùöéùöïùöïùöéùöõ     1   1\n",
       "\n",
       "[9269 rows x 2 columns]"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "b09de9ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "data['tweet_text']=data['tweet_text'].apply(lambda x: mapping_replacer(x, contraction))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "92dc9bfb",
   "metadata": {},
   "outputs": [],
   "source": [
    "data['tweet_text'] = data['tweet_text'].apply(lambda x:clean_text(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "053670e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "data['tweet_text']=data['tweet_text'].apply(lambda x: remove_stopword(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "f338ac49",
   "metadata": {},
   "outputs": [],
   "source": [
    "data['tweet_text']=data['tweet_text'].apply(lambda x: lexicon_normalization(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "9f1cea3e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>_key</th>\n",
       "      <th>tweet_author</th>\n",
       "      <th>tweet_text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1374140386071961602</td>\n",
       "      <td>Hematopoiesis News</td>\n",
       "      <td>[sci, conduc, phas, ii, study, acalabrutinib, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1374032432173842437</td>\n",
       "      <td>Michael Wang MD</td>\n",
       "      <td>[phas, acalabrutinib, venetoclax, av, tri, sti...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1373902876553048065</td>\n",
       "      <td>1stOncology</td>\n",
       "      <td>[nic, back, astrazeneca, calqu, cll, http, co]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1373656782367813635</td>\n",
       "      <td>Toby Eyre</td>\n",
       "      <td>[acalabrutinib, valu, opt, pt, intol, ibrutini...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1372941634334232586</td>\n",
       "      <td>Lymphoma Hub</td>\n",
       "      <td>[nic, recommend, u, acalabrutinib, paty, tre, ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  _key        tweet_author  \\\n",
       "0  1374140386071961602  Hematopoiesis News   \n",
       "1  1374032432173842437     Michael Wang MD   \n",
       "2  1373902876553048065         1stOncology   \n",
       "3  1373656782367813635           Toby Eyre   \n",
       "4  1372941634334232586        Lymphoma Hub   \n",
       "\n",
       "                                          tweet_text  \n",
       "0  [sci, conduc, phas, ii, study, acalabrutinib, ...  \n",
       "1  [phas, acalabrutinib, venetoclax, av, tri, sti...  \n",
       "2     [nic, back, astrazeneca, calqu, cll, http, co]  \n",
       "3  [acalabrutinib, valu, opt, pt, intol, ibrutini...  \n",
       "4  [nic, recommend, u, acalabrutinib, paty, tre, ...  "
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b949882f",
   "metadata": {},
   "source": [
    "## Polarity Of Sentiment\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "0aa3d897",
   "metadata": {},
   "outputs": [],
   "source": [
    "from wordcloud import WordCloud, STOPWORDS , ImageColorGenerator\n",
    "\n",
    "from textblob import TextBlob\n",
    "\n",
    "def get_tweet_sentiment(tweet): \n",
    "    ''' \n",
    "    Utility function to classify sentiment of passed tweet \n",
    "    using textblob's sentiment method \n",
    "    '''\n",
    "    # create TextBlob object of passed tweet text \n",
    "    analysis = TextBlob(tweet) \n",
    "    \n",
    "    # set sentiment \n",
    "    if analysis.sentiment.polarity > 0:\n",
    "        return 'positive'\n",
    "    elif analysis.sentiment.polarity == 0: \n",
    "        return 'neutral'\n",
    "    else: \n",
    "        return 'negative'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "fa8841ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "data['sentiment']=data['tweet_text'].apply(lambda x: get_tweet_sentiment(' '.join(x)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "1736e73c",
   "metadata": {},
   "outputs": [],
   "source": [
    "data.to_csv(path_or_buf='C:\\\\Users\\\\Ansh\\\\Desktop\\\\data.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "c6cfd109",
   "metadata": {},
   "outputs": [],
   "source": [
    "Positive_sent = data[data['sentiment']=='positive']\n",
    "Negative_sent = data[data['sentiment']=='negative']\n",
    "Neutral_sent = data[data['sentiment']=='neutral']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "e34a6703",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of tweets with positive sentiment 12832\n",
      "Number of tweets with negative sentiment 3207\n",
      "Number of tweets with neutral sentiment 27308\n"
     ]
    }
   ],
   "source": [
    "print('Number of tweets with positive sentiment', Positive_sent['sentiment'].count())\n",
    "print('Number of tweets with negative sentiment', Negative_sent['sentiment'].count())\n",
    "print('Number of tweets with neutral sentiment', Neutral_sent['sentiment'].count())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29afdf09",
   "metadata": {},
   "source": [
    "#### Here we got to know that for finding out the polarity we need to clean the data, remove stopwords and tokenise the tweets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df394247",
   "metadata": {},
   "outputs": [],
   "source": [
    "top = Counter([item for sublist in data['tweet_text'] for item in sublist])\n",
    "temp = pd.DataFrame(top.most_common(20))\n",
    "temp.columns = ['Common_words','count']\n",
    "temp.style.background_gradient(cmap='Blues')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "adf3aa47",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = px.bar(temp, x=\"count\", y=\"Common_words\", title='Commmon Words in Selected Text', orientation='h', \n",
    "             width=700, height=700,color='Common_words')\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d08ec130",
   "metadata": {},
   "outputs": [],
   "source": [
    "top = Counter([item for sublist in data['tweet_text'] for item in sublist])\n",
    "temp = pd.DataFrame(top.most_common(20))\n",
    "temp = temp.iloc[1:,:]\n",
    "temp.columns = ['Common_words','count']\n",
    "temp.style.background_gradient(cmap='Purples')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "335b73f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = px.treemap(temp, path=['Common_words'], values='count',title='Tree of Most Common Words')\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b7b4c0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from wordcloud import WordCloud, STOPWORDS , ImageColorGenerator\n",
    "\n",
    "from textblob import TextBlob\n",
    "\n",
    "def get_tweet_sentiment(tweet): \n",
    "    ''' \n",
    "    Utility function to classify sentiment of passed tweet \n",
    "    using textblob's sentiment method \n",
    "    '''\n",
    "    # create TextBlob object of passed tweet text \n",
    "    analysis = TextBlob(tweet) \n",
    "    \n",
    "    # set sentiment \n",
    "    if analysis.sentiment.polarity > 0:\n",
    "        return 'positive'\n",
    "    elif analysis.sentiment.polarity == 0: \n",
    "        return 'neutral'\n",
    "    else: \n",
    "        return 'negative'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "051f6f32",
   "metadata": {},
   "outputs": [],
   "source": [
    "data['sentiment']=data['tweet_text'].apply(lambda x: get_tweet_sentiment(' '.join(x)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a9f5cde",
   "metadata": {},
   "outputs": [],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b6965b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "Positive_sent = data[data['sentiment']=='positive']\n",
    "Negative_sent = data[data['sentiment']=='negative']\n",
    "Neutral_sent = data[data['sentiment']=='neutral']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d11f9b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Number of tweets with positive sentiment', Positive_sent['sentiment'].count())\n",
    "print('Number of tweets with negative sentiment', Negative_sent['sentiment'].count())\n",
    "print('Number of tweets with neutral sentiment', Neutral_sent['sentiment'].count())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d90c4e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "#MosT common positive words\n",
    "top = Counter([item for sublist in Positive_sent['tweet_text'] for item in sublist])\n",
    "temp_positive = pd.DataFrame(top.most_common(20))\n",
    "temp_positive.columns = ['Common_words','count']\n",
    "temp_positive.style.background_gradient(cmap='Greens')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c564f09f",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import numpy as np\n",
    "top = Counter([item for sublist in Positive_sent['tweet_text'] for item in sublist])\n",
    "temp_positive = pd.DataFrame(top.most_common(23))\n",
    "temp_positive.columns = ['Common_words','count']\n",
    "temp_positive['Common_words'] = temp_positive['Common_words'].map(lambda x: re.sub(r'\\W+', '', x))\n",
    "temp_positive['Common_words'] = temp_positive['Common_words'].replace(r'\\W+', '', regex=True)\n",
    "temp_positive['Common_words'] = temp_positive['Common_words'].apply(lambda x:remove_spaces(x))\n",
    "temp_positive=temp_positive[~temp_positive['Common_words'].isin(['s','gre','‚Äú',' * '])] #new line removing meaningless words\n",
    "mask1 = temp_positive.Common_words.str.contains('[a-zA-Z]')\n",
    "mask2 = temp_positive.Common_words.notna()\n",
    "temp_positive = temp_positive[mask1 | mask2]\n",
    "temp_positive.Common_words =  temp_positive.Common_words.str.replace(r\"\\s+\", \"\").replace(\"\", np.NaN)\n",
    "temp_positive=temp_positive.dropna()\n",
    "\n",
    "\n",
    "temp_positive.style.background_gradient(cmap='Greens')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3aad2377",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = px.bar(temp_positive, x=\"count\", y=\"Common_words\", title='Most Commmon Words in Positive Sentiment tweets', orientation='h', \n",
    "             width=700, height=700,color='Common_words')\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c61a90a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#MosT common negative words\n",
    "top = Counter([item for sublist in Negative_sent['tweet_text'] for item in sublist])\n",
    "temp_negative = pd.DataFrame(top.most_common(20))\n",
    "temp_negative = temp_negative.iloc[1:,:]\n",
    "temp_negative.columns = ['Common_words','count']\n",
    "temp_negative.style.background_gradient(cmap='Reds')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5937d286",
   "metadata": {},
   "outputs": [],
   "source": [
    "#MosT common negative words\n",
    "top = Counter([item for sublist in Negative_sent['tweet_text'] for item in sublist])\n",
    "temp_negative = pd.DataFrame(top.most_common(22))\n",
    "temp_negative = temp_negative.iloc[1:,:]\n",
    "temp_negative.columns = ['Common_words','count']\n",
    "\n",
    "#Data cleaning\n",
    "temp_negative['Common_words'] = temp_negative['Common_words'].map(lambda x: re.sub(r'\\W+', '', x))\n",
    "temp_negative['Common_words'] = temp_negative['Common_words'].replace(r'\\W+', '', regex=True)\n",
    "temp_negative=temp_negative[~temp_negative['Common_words'].isin(['s','t'])] #new line removing meaningless words from above\n",
    "#mask1 = temp_negative.Common_words.str.contains('[a-zA-Z]')\n",
    "#mask2 = temp_negative.Common_words.notna()\n",
    "#temp_negative = temp_negative[mask1 | mask2]\n",
    "\n",
    "temp_negative.Common_words =  temp_negative.Common_words.replace(\"\", np.nan)\n",
    "temp_negative = temp_negative.dropna(subset=['Common_words'])\n",
    "\n",
    "temp_negative.style.background_gradient(cmap='Reds')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "536ce197",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = px.treemap(temp_negative, path=['Common_words'], values='count',title='Tree Of Most Common Words in Negative Tweets')\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e39d14a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "#MosT common Neutral words\n",
    "top = Counter([item for sublist in Neutral_sent['tweet_text'] for item in sublist])\n",
    "temp_neutral = pd.DataFrame(top.most_common(20))\n",
    "temp_neutral = temp_neutral.loc[1:,:]\n",
    "temp_neutral.columns = ['Common_words','count']\n",
    "temp_neutral.style.background_gradient(cmap='YlOrBr')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5913334",
   "metadata": {},
   "outputs": [],
   "source": [
    "top = Counter([item for sublist in Neutral_sent['tweet_text'] for item in sublist])\n",
    "temp_neutral = pd.DataFrame(top.most_common(20))\n",
    "temp_neutral = temp_neutral.loc[1:,:]\n",
    "temp_neutral.columns = ['Common_words','count']\n",
    "\n",
    "#Data cleaning\n",
    "temp_neutral['Common_words'] = temp_neutral['Common_words'].map(lambda x: re.sub(r'\\W+', '', x))\n",
    "temp_neutral['Common_words'] = temp_neutral['Common_words'].replace(r'\\W+', '', regex=True)\n",
    "temp_neutral=temp_neutral[~temp_neutral['Common_words'].isin(['s'])] #new line removing meaningless words from above\n",
    "\n",
    "temp_neutral.Common_words =  temp_neutral.Common_words.replace(\"\", np.nan)\n",
    "temp_neutral = temp_neutral.dropna(subset=['Common_words'])\n",
    "\n",
    "temp_neutral.style.background_gradient(cmap='YlOrBr')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30cb2daf",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = px.bar(temp_neutral, x=\"count\", y=\"Common_words\", title='Most Commmon Neutral Words', orientation='h', \n",
    "             width=700, height=700,color='Common_words')\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29f049dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = px.treemap(temp_neutral, path=['Common_words'], values='count',title='Tree Of Most Common Neutral Words')\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a50e6dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_text = [word for word_list in data['tweet_text'] for word in word_list]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "617ddd59",
   "metadata": {},
   "outputs": [],
   "source": [
    "def words_unique(sentiment,numwords,raw_words):\n",
    "    '''\n",
    "    Input:\n",
    "        segment - Segment category (ex. 'Neutral');\n",
    "        numwords - how many specific words do you want to see in the final result; \n",
    "        raw_words - list  for item in train_data[train_data.segments == segments]['temp_list1']:\n",
    "    Output: \n",
    "        dataframe giving information about the name of the specific ingredient and how many times it occurs in the chosen cuisine (in descending order based on their counts)..\n",
    "\n",
    "    '''\n",
    "    allother = []\n",
    "    for item in data[data.sentiment != sentiment]['tweet_text']:\n",
    "        for word in item:\n",
    "            allother .append(word)\n",
    "    allother  = list(set(allother ))\n",
    "    \n",
    "    specificnonly = [x for x in raw_text if x not in allother]\n",
    "    \n",
    "    mycounter = Counter()\n",
    "    \n",
    "    for item in data[data.sentiment == sentiment]['tweet_text']:\n",
    "        for word in item:\n",
    "            mycounter[word] += 1\n",
    "    keep = list(specificnonly)\n",
    "    \n",
    "    for word in list(mycounter):\n",
    "        if word not in keep:\n",
    "            del mycounter[word]\n",
    "    \n",
    "    Unique_words = pd.DataFrame(mycounter.most_common(numwords), columns = ['words','count'])\n",
    "    \n",
    "    return Unique_words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42967a1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "Unique_Positive= words_unique('positive', 20, raw_text)\n",
    "print(\"The top 20 unique words in Positive Tweets are:\")\n",
    "Unique_Positive.style.background_gradient(cmap='Greens')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59faf7f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = px.treemap(Unique_Positive, path=['words'], values='count',title='Tree Of Unique Words in Positive sentiment tweets')\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6b960db",
   "metadata": {},
   "outputs": [],
   "source": [
    "from palettable.colorbrewer.qualitative import Pastel1_7\n",
    "plt.figure(figsize=(16,10))\n",
    "my_circle=plt.Circle((0,0), 0.7, color='white')\n",
    "plt.pie(Unique_Positive['count'], labels=Unique_Positive.words, colors=Pastel1_7.hex_colors)\n",
    "p=plt.gcf()\n",
    "p.gca().add_artist(my_circle)\n",
    "plt.title('Donut Plot Of Unique words in Positive sentiment tweets')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a349eb27",
   "metadata": {},
   "outputs": [],
   "source": [
    "Unique_Negative= words_unique('negative', 10, raw_text)\n",
    "print(\"The top 10 unique words in Negative Tweets are:\")\n",
    "Unique_Negative.style.background_gradient(cmap='Reds')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33621bf3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from palettable.colorbrewer.qualitative import Pastel1_7\n",
    "plt.figure(figsize=(16,10))\n",
    "my_circle=plt.Circle((0,0), 0.7, color='white')\n",
    "plt.rcParams['text.color'] = 'black'\n",
    "plt.pie(Unique_Negative['count'], labels=Unique_Negative.words, colors=Pastel1_7.hex_colors)\n",
    "p=plt.gcf()\n",
    "p.gca().add_artist(my_circle)\n",
    "plt.title('DoNut Plot Of Unique words in Negative sentiment tweets')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "632511da",
   "metadata": {},
   "outputs": [],
   "source": [
    "Unique_Neutral= words_unique('neutral', 10, raw_text)\n",
    "print(\"The top 10 unique words in Neutral Tweets are:\")\n",
    "Unique_Neutral.style.background_gradient(cmap='YlOrBr')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ed01338",
   "metadata": {},
   "outputs": [],
   "source": [
    "from palettable.colorbrewer.qualitative import Pastel1_7\n",
    "plt.figure(figsize=(16,10))\n",
    "my_circle=plt.Circle((0,0), 0.7, color='white')\n",
    "plt.pie(Unique_Neutral['count'], labels=Unique_Neutral.words, colors=Pastel1_7.hex_colors)\n",
    "p=plt.gcf()\n",
    "p.gca().add_artist(my_circle)\n",
    "plt.title('DoNut Plot Of Unique words in Neutral sentiment tweets')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36449bfc",
   "metadata": {},
   "source": [
    "# Word Cloud \n",
    "### For Positive, Neutral, Negative Sentiments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "627c1055",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_wordcloud(text, mask=None, max_words=200, max_font_size=100, figure_size=(24.0,16.0), color = 'white',\n",
    "                   title = None, title_size=40, image_color=False):\n",
    "    \n",
    "    wordcloud = WordCloud(background_color=color,\n",
    "                    max_words = max_words,\n",
    "                    max_font_size = max_font_size, \n",
    "                    random_state = 42,\n",
    "                    width=400, \n",
    "                    height=200,\n",
    "                    mask = mask)\n",
    "    wordcloud.generate(str(text))\n",
    "    \n",
    "    plt.figure(figsize=figure_size)\n",
    "    if image_color:\n",
    "        image_colors = ImageColorGenerator(mask);\n",
    "        plt.imshow(wordcloud.recolor(color_func=image_colors), interpolation=\"bilinear\");\n",
    "        plt.title(title, fontdict={'size': title_size,  \n",
    "                                  'verticalalignment': 'bottom'})\n",
    "    else:\n",
    "        plt.imshow(wordcloud);\n",
    "        plt.title(title, fontdict={'size': title_size, 'color': 'black', \n",
    "                                  'verticalalignment': 'bottom'})\n",
    "    plt.axis('off');\n",
    "    plt.tight_layout()  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "543004b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_wordcloud(Neutral_sent.tweet_text,color='white',max_font_size=100,title_size=30,title=\"WordCloud of Neutral Tweets\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d5885ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_wordcloud(Positive_sent.tweet_text,title=\"Word Cloud Of Positive tweets\",title_size=30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c12eb38",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_wordcloud(Negative_sent.tweet_text,title=\"Word Cloud Of Negative tweets\",title_size=30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c50c760",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
